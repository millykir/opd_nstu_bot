#!/usr/bin/env python3
# coding: utf-8
"""
–°–∫—Ä–∏–ø—Ç ‚Ññ1 (v2): –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Ollama.
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ 25 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤.
"""
import json
import requests
import time
from pathlib import Path
from tqdm import tqdm
import re

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
PROJECT_ROOT = Path(__file__).parent
INPUT_DATA_PATH = PROJECT_ROOT / "data/opd_dataset.json" # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∑–¥–µ—Å—å –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Å 1 –≤–æ–ø—Ä–æ—Å–æ–º
OUTPUT_DATA_PATH = PROJECT_ROOT / "data/opd_dataset_augmented.json"

OLLAMA_HOST = "http://localhost:11434"
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏! Llama3 –∏–ª–∏ Gemma —Å–ø—Ä–∞–≤—è—Ç—Å—è –æ—Ç–ª–∏—á–Ω–æ.
OLLAMA_MODEL_FOR_AUGMENTATION = "gpt-oss:20b" 

# --- –ò–ó–ú–ï–ù–ï–ù–ò–ï ‚Ññ1: –ü—Ä–æ—Å–∏–º 25 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ ---
PROMPT_TEMPLATE = """
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å, —Å–æ–∑–¥–∞–≤ 25 –µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤.
–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Å—Ç–∏–ª–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞: –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫, —Å–∏–Ω–æ–Ω–∏–º—ã, –º–æ–∂–µ—à—å –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ–º–Ω–æ–≥–æ —Å–ª–µ–Ω–≥–∞, –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ–¥ —Ä–∞–∑–Ω—ã–º–∏ —É–≥–ª–∞–º–∏.

–í–ê–ñ–ù–û–ï –ü–†–ê–í–ò–õ–û: –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON-–º–∞—Å—Å–∏–≤–æ–º –∏–∑ 25 —Å—Ç—Ä–æ–∫. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ.

[–ü–†–ò–ú–ï–†]
–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –í–û–ü–†–û–°:
"–ú–æ–∂–Ω–æ –ª–∏ –Ω–µ –ø–æ—Å–µ—â–∞—Ç—å –∑–∞–Ω—è—Ç–∏—è –ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ ¬´–û—Å–Ω–æ–≤—ã –ø—Ä–æ–µ–∫—Ç–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏¬ª"

–¢–í–û–ô –û–¢–í–ï–¢ (–ø—Ä–∏–º–µ—Ä –¥–ª—è 5, –Ω–æ —Ç—ã –¥–æ–ª–∂–µ–Ω —Å–¥–µ–ª–∞—Ç—å 25):
[
    "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ª–∏ —Ö–æ–¥–∏—Ç—å –Ω–∞ –æ–ø–¥",
    "—á—Ç–æ –±—É–¥–µ—Ç –µ—Å–ª–∏ —è –Ω–µ –ø—Ä–∏–¥—É –Ω–∞ –æ–ø–¥",
    "–º–æ–∂–Ω–æ –Ω–µ —Ö–æ–¥–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤—ã –ø—Ä–æ–µ–∫—Ç–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
    "–ø—Ä–æ–≥—É–ª—è—Ç—å –æ–ø–¥ –º–æ–∂–Ω–æ?",
    "–∫–∞–∫–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –∑–∞ –ø—Ä–æ–ø—É—Å–∫ –æ–ø–¥"
]
[/–ü–†–ò–ú–ï–†]

–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –í–û–ü–†–û–°:
"{question}"

–¢–í–û–ô –û–¢–í–ï–¢:
"""

def call_ollama_for_variations(question: str) -> list[str]:
    prompt = PROMPT_TEMPLATE.format(question=question)
    url = f"{OLLAMA_HOST}/api/generate"
    payload = {
        "model": OLLAMA_MODEL_FOR_AUGMENTATION,
        "prompt": prompt, "temperature": 0.7, "stream": False,
    }
    try:
        response = requests.post(url, json=payload, timeout=180) # –£–≤–µ–ª–∏—á–∏–º —Ç–∞–π–º–∞—É—Ç
        response.raise_for_status()
        raw_text = response.json().get("response", "").strip()
        
        match = re.search(r'\[.*\]', raw_text, re.DOTALL)
        if match:
            try:
                variations = json.loads(match.group(0))
                if isinstance(variations, list) and len(variations) > 0:
                    return [str(v) for v in variations]
            except json.JSONDecodeError:
                print(f"\n–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {question}")
    except requests.exceptions.RequestException as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}")
    return []

def main():
    if not INPUT_DATA_PATH.exists():
        print(f"‚ùå –û–®–ò–ë–ö–ê: –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_DATA_PATH}"); return

    print(f"‚ñ∂Ô∏è  –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ {INPUT_DATA_PATH.name}...")
    with open(INPUT_DATA_PATH, 'r', encoding='utf-8') as f:
        # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –∏–º–µ–µ—Ç —Ñ–æ—Ä–º–∞—Ç {"question": "...", "answer": "..."}
        original_data = json.load(f)

    augmented_dataset = []
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é {len(original_data)} –∑–∞–ø–∏—Å–µ–π. –≠—Ç–æ –∑–∞–π–º–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è...")

    for item in tqdm(original_data, desc="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤"):
        # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–ª—é—á "question"
        original_question = item.get("question")
        if not original_question: continue
            
        variations = call_ollama_for_variations(original_question)
        unique_questions = list(dict.fromkeys([original_question] + variations))
        
        new_item = {
            "id": item["id"], "questions": unique_questions, "answer": item["answer"],
            "topic": item["topic"], "source": item["source"]
        }
        augmented_dataset.append(new_item)
        time.sleep(0.5)

    print(f"\n‚úÖ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {sum(len(i['questions']) for i in augmented_dataset)} –≤–æ–ø—Ä–æ—Å–æ–≤.")
    
    with open(OUTPUT_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(augmented_dataset, f, ensure_ascii=False, indent=2)
    print(f"üéâ –ù–æ–≤—ã–π –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {OUTPUT_DATA_PATH}")

if __name__ == "__main__":
    main()