import re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from datetime import datetime
import os
import warnings

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
LOG_FILE = 'chat_qa_log.txt'
OUTPUT_DIR = 'analytics_pro_report'

warnings.simplefilter(action='ignore')
plt.style.use('seaborn-v0_8-whitegrid')

STOPWORDS = {
    '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞', '—Ç–∞–∫', '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞', '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ', '–º–Ω–µ', '–±—ã–ª–æ', '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç', '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞', '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥', '–ª–∏', '–µ—Å–ª–∏', '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ', '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å', '—É–∂', '–≤–∞–º', '–≤–µ–¥—å', '—Ç–∞–º', '–ø–æ—Ç–æ–º', '—Å–µ–±—è', '–Ω–∏—á–µ–≥–æ', '–µ–π', '–º–æ–∂–µ—Ç', '–æ–Ω–∏', '—Ç—É—Ç', '–≥–¥–µ', '–µ—Å—Ç—å', '–Ω–∞–¥–æ', '–Ω–µ–π', '–¥–ª—è', '–º—ã', '—Ç–µ–±—è', '–∏—Ö', '—á–µ–º', '–±—ã–ª–∞', '—Å–∞–º', '—á—Ç–æ–±', '–±–µ–∑', '–±—É–¥—Ç–æ', '—á–µ–≥–æ', '—Ä–∞–∑', '—Ç–æ–∂–µ', '—Å–µ–±–µ', '–ø–æ–¥', '–±—É–¥–µ—Ç', '–∂', '—Ç–æ–≥–¥–∞', '–∫—Ç–æ', '—ç—Ç–æ—Ç', '—Ç–æ–≥–æ', '–ø–æ—Ç–æ–º—É', '—ç—Ç–æ–≥–æ', '–∫–∞–∫–æ–π', '—Å–æ–≤—Å–µ–º', '–Ω–∏–º', '–∑–¥–µ—Å—å', '—ç—Ç–æ–º', '–æ–¥–∏–Ω', '–ø–æ—á—Ç–∏', '–º–æ–π', '—Ç–µ–º', '—á—Ç–æ–±—ã', '–Ω–µ–µ', '—Å–µ–π—á–∞—Å', '–±—ã–ª–∏', '–∫—É–¥–∞', '–∑–∞—á–µ–º', '–≤—Å–µ—Ö', '–Ω–∏–∫–æ–≥–¥–∞', '–º–æ–∂–Ω–æ', '–ø—Ä–∏', '–Ω–∞–∫–æ–Ω–µ—Ü', '–¥–≤–∞', '–æ–±', '–¥—Ä—É–≥–æ–π', '—Ö–æ—Ç—å', '–ø–æ—Å–ª–µ', '–Ω–∞–¥', '–±–æ–ª—å—à–µ', '—Ç–æ—Ç', '—á–µ—Ä–µ–∑', '—ç—Ç–∏', '–Ω–∞—Å', '–ø—Ä–æ', '–≤—Å–µ–≥–æ', '–Ω–∏—Ö', '–∫–∞–∫–∞—è', '–º–Ω–æ–≥–æ', '—Ä–∞–∑–≤–µ', '—Ç—Ä–∏', '—ç—Ç—É', '–º–æ—è', '–≤–ø—Ä–æ—á–µ–º', '—Ö–æ—Ä–æ—à–æ', '—Å–≤–æ—é', '—ç—Ç–æ–π', '–ø–µ—Ä–µ–¥', '–∏–Ω–æ–≥–¥–∞', '–ª—É—á—à–µ', '—á—É—Ç—å', '—Ç–æ–º', '–Ω–µ–ª—å–∑—è', '—Ç–∞–∫–æ–π', '–∏–º', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–∫–æ–Ω–µ—á–Ω–æ', '–≤—Å—é', '–º–µ–∂–¥—É', '–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ', '—Å–ø–∞—Å–∏–±–æ', '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', '–±–æ—Ç', '–ø–æ–¥—Å–∫–∞–∂–∏', '—Å–∫–∞–∂–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏'
}

def parse_log_file(filepath):
    print(f"DEBUG: –ß–∏—Ç–∞—é —Ñ–∞–π–ª {filepath}...")
    data = []
    current_entry = {}
    
    patterns = {
        'user_id': re.compile(r'^UserID:\s*(.*)'),
        'timestamp': re.compile(r'^–í—Ä–µ–º—è —Å–æ–æ–±—â–µ–Ω–∏—è:\s*(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})'),
        'latency': re.compile(r'^–ó–∞–¥–µ—Ä–∂–∫–∞ \(—Å–µ–∫\):\s*([\d\.]+)'),
    }
    
    with open(filepath, 'r', encoding='utf-8', errors='replace') as f:
        lines = f.readlines()

    print(f"DEBUG: –ü—Ä–æ—á–∏—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(lines)}")
    
    q_buf, a_buf = [], []
    state = 'META' 

    for i, line in enumerate(lines):
        line = line.strip()
        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∏–ª–∏ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
        if line.startswith('----------'):
            if current_entry and ('question' in current_entry or q_buf):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ
                current_entry['question'] = " ".join(q_buf).strip()
                current_entry['answer'] = " ".join(a_buf).strip()
                # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–∞ –Ω–µ—Ç, —Å—Ç–∞–≤–∏–º –∑–∞–≥–ª—É—à–∫—É, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –∑–∞–ø–∏—Å—å
                if not current_entry['question']: current_entry['question'] = "<Empty>"
                data.append(current_entry)
            
            # –°–±—Ä–æ—Å
            current_entry = {}
            q_buf, a_buf = [], []
            state = 'META'
            continue

        if line.startswith('Q:'):
            state = 'Q'
            clean_line = line[2:].strip()
            if clean_line: q_buf.append(clean_line)
        elif line.startswith('A:'):
            state = 'A'
            clean_line = line[2:].strip()
            if clean_line: a_buf.append(clean_line)
        else:
            if state == 'Q': q_buf.append(line)
            elif state == 'A': a_buf.append(line)
            else:
                for key, pattern in patterns.items():
                    match = pattern.match(line)
                    if match:
                        val = match.group(1).strip()
                        if key == 'latency':
                            try: current_entry[key] = float(val)
                            except: pass
                        elif key == 'timestamp':
                            try: current_entry['datetime'] = datetime.strptime(val, '%Y-%m-%d %H:%M:%S')
                            except: pass
                        else:
                            current_entry[key] = val

    # –ü–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–ø–∏—Å—å
    if current_entry and q_buf:
        current_entry['question'] = " ".join(q_buf).strip()
        current_entry['answer'] = " ".join(a_buf).strip()
        data.append(current_entry)

    print(f"DEBUG: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π (–¥–∏–∞–ª–æ–≥–æ–≤): {len(data)}")
    return pd.DataFrame(data)

def get_ngrams(text_series, n=2, top_k=10):
    ngrams_list = []
    # –†–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –Ω–µ–ø—É—Å—Ç—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏
    valid_texts = text_series.dropna().astype(str)
    for text in valid_texts:
        if text == "<Empty>": continue
        text = re.sub(r'[^\w\s]', '', text.lower())
        words = [w for w in text.split() if w not in STOPWORDS and len(w) > 2]
        if len(words) >= n:
            ngrams_list.extend(zip(*[words[i:] for i in range(n)]))
    return Counter(ngrams_list).most_common(top_k)

def generate_report():
    df = parse_log_file(LOG_FILE)
    if df.empty:
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")
        return

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –¥–∞–Ω–Ω—ã–µ —Å –¥–∞—Ç–∞–º–∏ –∏ –±–µ–∑
    df_time = df.dropna(subset=['datetime'])
    print(f"DEBUG: –ó–∞–ø–∏—Å–µ–π —Å –¥–∞—Ç–∞–º–∏ (–¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤): {len(df_time)}")
    print(f"DEBUG: –ó–∞–ø–∏—Å–µ–π –≤—Å–µ–≥–æ (–¥–ª—è —Ç–µ–∫—Å—Ç–∞): {len(df)}")

    # 1. RAG Success Rate (–±–µ—Ä–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ)
    if 'answer' in df.columns:
        fail_phrases = ['–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é', '–Ω–µ –Ω–∞—à–µ–ª', '–Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏', '–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫']
        df['is_failure'] = df['answer'].fillna('').str.lower().apply(lambda x: any(p in x for p in fail_phrases))
        failure_rate = df['is_failure'].mean() * 100
        success_rate = 100 - failure_rate
        
        plt.figure(figsize=(6, 6))
        plt.pie([success_rate, failure_rate], labels=['–£—Å–ø–µ—Ö', '–ë–∞–∑–∞ –Ω–µ –∑–Ω–∞–µ—Ç'], 
                autopct='%1.1f%%', colors=['#4CAF50', '#F44336'])
        plt.title('–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π')
        plt.savefig(f'{OUTPUT_DIR}/1_quality.png')
        print(f"üìä –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤: {success_rate:.1f}%")

    # 2. –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Ç–æ–ª—å–∫–æ –≥–¥–µ –µ—Å—Ç—å –¥–∞—Ç—ã)
    if not df_time.empty:
        df_time['hour'] = df_time['datetime'].dt.hour
        df_time['weekday'] = df_time['datetime'].dt.day_name()
        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        
        hm_data = df_time.pivot_table(index='weekday', columns='hour', values='question', aggfunc='count', fill_value=0)
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–Ω–µ–π
        existing_days = [d for d in days if d in hm_data.index]
        hm_data = hm_data.reindex(existing_days)
        
        plt.figure(figsize=(10, 5))
        sns.heatmap(hm_data, cmap='Blues', annot=False)
        plt.title('–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏')
        plt.tight_layout()
        plt.savefig(f'{OUTPUT_DIR}/2_heatmap.png')
        print("üìä –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞.")

    # 3. NLP –ê–Ω–∞–ª–∏–∑ (–±–µ—Ä–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ)
    if 'question' in df.columns:
        bigrams = get_ngrams(df['question'], n=2, top_k=10)
        if bigrams:
            plt.figure(figsize=(10, 6))
            phrases, counts = zip(*bigrams)
            phrases_str = [" ".join(p) for p in phrases]
            sns.barplot(x=list(counts), y=list(phrases_str), palette='viridis')
            plt.title('–¢–æ–ø –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–º')
            plt.tight_layout()
            plt.savefig(f'{OUTPUT_DIR}/3_topics.png')
            print("üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω.")

    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel
    df.to_excel(f'{OUTPUT_DIR}/report.xlsx', index=False)
    print(f"\n‚úÖ –ì–û–¢–û–í–û! –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ø–∞–ø–∫—É {OUTPUT_DIR}")

if __name__ == "__main__":
    generate_report()
